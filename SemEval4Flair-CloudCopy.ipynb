{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:45.203849Z",
     "start_time": "2019-04-20T00:14:45.192877Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dev.data',\n",
       " 'SemEval15DataFiles',\n",
       " 'test.data',\n",
       " 'test.label',\n",
       " 'train.data',\n",
       " 'tweetText.txt',\n",
       " 'tweetTextFromDevData',\n",
       " 'tweetTextFromDevData_parsed.txt',\n",
       " 'tweetTextFromTestData',\n",
       " 'tweetTextFromTestData_parsed.txt',\n",
       " 'tweetTextFromTrainData',\n",
       " 'tweetTextFromTrainData_parsed.txt',\n",
       " 'tweetText_parsed.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install flair\n",
    "# !pip install tqdm\n",
    "# !ls -lh\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(\"d:\\\\Thesis\\\\SemEval15\\\\SemEval-PIT2015-github\\\\data\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:47.698493Z",
     "start_time": "2019-04-20T00:14:45.205841Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets load the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:49.599546Z",
     "start_time": "2019-04-20T00:14:47.701304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to download the data file ...\n",
      "Extracted downloaded data file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data.zip', 'dev.data', 'test.data', 'test.label', 'train.data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "baseDir = os.getcwd()\n",
    "dataDir = baseDir + os.sep + \"/SemEval15DataFiles/\"\n",
    "os.makedirs(dataDir, exist_ok=True)\n",
    "os.chdir(dataDir)\n",
    "\n",
    "url = 'https://github.com/upmangaurav/t2v/raw/master/data/data.zip'\n",
    "print('Beginning to download the data file ...')\n",
    "urllib.request.urlretrieve(url, dataDir + 'data.zip')\n",
    "\n",
    "zip_ref = zipfile.ZipFile('data.zip', 'r')\n",
    "zip_ref.extractall(dataDir)\n",
    "print('Extracted downloaded data file...')\n",
    "zip_ref.close()\n",
    "\n",
    "!ls -lh\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:49.611525Z",
     "start_time": "2019-04-20T00:14:49.603500Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_List(file):\n",
    "    debatableCount = 0\n",
    "    with open(file, 'r') as f:\n",
    "        td = f.readlines()\n",
    "\n",
    "    dataList = []\n",
    "    print(\"\\nSize of Dataset\", file, str(len(td)))\n",
    "    for item in td:\n",
    "        trainDict = {}\n",
    "        splitsie = item.split('\\t')\n",
    "\n",
    "        #For training and dev data:\n",
    "        if len(splitsie[4]) > 1:\n",
    "            #debatable if only 2 turkers voted similar\n",
    "            if splitsie[4][1] == '2':\n",
    "                debatableCount += 1\n",
    "                continue\n",
    "        #Convert Label such as (3, 2) to decimal value like 0.6\n",
    "            else: trainDict['Label'] = 0.2 * int(splitsie[4][1])\n",
    "\n",
    "        else: # Test data:\n",
    "            if splitsie[4] == '2':\n",
    "                debatableCount += 1\n",
    "                continue\n",
    "\n",
    "            else: trainDict['Label'] = 0.2 * int(splitsie[4])\n",
    "\n",
    "        \n",
    "        trainDict['Topic_Id'] = splitsie[0]\n",
    "        trainDict['Topic_Name'] = splitsie[1]\n",
    "        trainDict['Sent_1'] = splitsie[2]\n",
    "        trainDict['Sent_2'] = splitsie[3]\n",
    "\n",
    "\n",
    "        dataList.append(trainDict)\n",
    "    \n",
    "    print(\"Debatable thus ignored tweet-combo count: \", debatableCount)\n",
    "    print(\"Final dataset size:\", len(dataList))\n",
    "    return dataList "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:49.752109Z",
     "start_time": "2019-04-20T00:14:49.615471Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of Dataset train.data 13063\n",
      "Debatable thus ignored tweet-combo count:  1533\n",
      "Final dataset size: 11530\n",
      "\n",
      "Size of Dataset test.data 972\n",
      "Debatable thus ignored tweet-combo count:  130\n",
      "Final dataset size: 842\n",
      "\n",
      "Size of Dataset dev.data 4727\n",
      "Debatable thus ignored tweet-combo count:  585\n",
      "Final dataset size: 4142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'But my bro from the 757 EJ Manuel is the 1st QB gone'},\n",
       " {'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'Can believe EJ Manuel went as the 1st QB in the draft'},\n",
       " {'Label': 0.6000000000000001,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'EJ MANUEL IS THE 1ST QB what'},\n",
       " {'Label': 0.8,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'Manuel is the 1st QB to get drafted'},\n",
       " {'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'My boy EJ Manuel being the 1st QB picked'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainList = make_List('train.data')\n",
    "testList = make_List('test.data')\n",
    "devList = make_List('dev.data')\n",
    "trainList[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:50.060279Z",
     "start_time": "2019-04-20T00:14:49.754097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050 Ti'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:55.626983Z",
     "start_time": "2019-04-20T00:14:50.065265Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, DocumentRNNEmbeddings, Sentence\n",
    "#, ELMoEmbeddings, BertEmbeddings\n",
    "# BytePairEmbeddings\n",
    "\n",
    "#BytePair Embeddings\n",
    "# BytePairEmbedding = BytePairEmbeddings('en')\n",
    "\n",
    "# initialize the word embeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('mix-forward')\n",
    "flair_embedding_backward = FlairEmbeddings('mix-backward')\n",
    "# bert_embedding = BertEmbeddings('bert-large-cased')\n",
    "# elmo_embedding = ELMoEmbeddings()\n",
    "\n",
    "embeddings = [\n",
    "#                                               elmo_embedding\n",
    "#                                               BytePairEmbedding, \n",
    "                                              glove_embedding,\n",
    "#                                               flair_embedding_backward,\n",
    "#                                               flair_embedding_forward,\n",
    "#                                              bert_embedding\n",
    "] \n",
    "\n",
    "# initialize the document embeddings, mode = mean\n",
    "document_embeddings = DocumentRNNEmbeddings(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:55.685796Z",
     "start_time": "2019-04-20T00:14:55.628946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.5214e-01,  4.0450e-02,  6.9801e-01, -1.4999e-01,  2.9095e-01,\n",
      "         6.0819e-01, -7.0817e-01,  6.2955e-02,  8.3700e-01, -7.0492e-01,\n",
      "         5.6426e-01, -9.5148e-02,  1.2830e-02, -5.3448e-01,  1.9840e-01,\n",
      "         5.9018e-01,  1.8226e-01,  4.3688e-01, -7.5381e-02,  7.8457e-01,\n",
      "        -5.8933e-01, -6.5748e-01,  7.3637e-02, -1.4729e-01,  5.4231e-01,\n",
      "        -2.7395e-02, -6.7368e-01, -5.0288e-01,  1.4738e-01, -3.6519e-01,\n",
      "        -3.7521e-03,  1.5221e+00, -4.9132e-01,  7.2426e-02,  9.7861e-02,\n",
      "         2.5034e-01, -1.8353e-01, -6.1457e-01,  5.3440e-01, -4.9145e-01,\n",
      "         1.0121e-01, -1.8739e-02, -3.6560e-01, -2.6097e-01, -8.7821e-01,\n",
      "         1.0591e-01, -5.6150e-01, -2.0758e-01,  5.3582e-01,  1.0921e-01,\n",
      "        -1.2925e-01,  7.0651e-02, -1.5121e-03,  1.2543e-01,  2.6603e-01,\n",
      "        -1.1057e+00, -1.5336e-01, -6.6789e-02,  1.5032e+00, -2.9650e-01,\n",
      "         3.8293e-01,  2.2578e-01,  5.3931e-01,  5.2797e-02,  2.5743e-01,\n",
      "         6.3961e-01,  5.2151e-01,  2.3681e-01, -1.0200e-01, -1.3282e-01,\n",
      "         3.6625e-01, -1.4197e-01,  1.0620e-01, -3.5427e-01,  1.8708e-01,\n",
      "         1.6061e-01,  8.1978e-02, -3.8965e-01,  3.9822e-01, -2.6086e-01,\n",
      "         5.8887e-01, -5.7293e-01, -5.8272e-01, -1.6024e-01, -1.0071e+00,\n",
      "        -7.2258e-03,  2.5396e-01,  1.9762e-01,  1.4446e-01,  7.0349e-02,\n",
      "         5.0969e-02,  5.5830e-01,  4.0361e-01, -8.9450e-01,  2.3548e-01,\n",
      "        -1.0269e-01,  1.9737e-01, -4.1121e-02, -6.1363e-02,  2.7293e-01])\n",
      "tensor([-0.0789,  0.4616,  0.5778, -0.7164, -0.1312,  0.4186, -0.2916,  0.5201,\n",
      "         0.0900, -0.3506,  0.5175,  0.5200,  0.1522,  0.4148, -0.1238, -0.3722,\n",
      "         0.0273,  0.7567, -0.8739,  0.5893,  0.4666,  0.6292,  0.0926, -0.0129,\n",
      "        -0.0152,  0.2557, -0.4302, -0.7767,  0.7145, -0.3834, -0.6964,  0.2352,\n",
      "         0.1140,  0.0278,  0.0714,  0.8741, -0.1281,  0.0636,  0.0679, -0.5018,\n",
      "        -0.2852, -0.0725, -0.5074, -0.6914, -0.5358, -0.1136, -0.3823, -0.1241,\n",
      "         0.0112, -1.1622,  0.0371, -0.1849,  0.0142,  0.8719, -0.0973, -2.3565,\n",
      "        -0.1455,  0.2828,  2.0053,  0.2344, -0.3830,  0.6954, -0.4492, -0.0942,\n",
      "         0.9053,  0.6576,  0.2763,  0.3069, -0.5778, -0.2299, -0.0830, -0.5724,\n",
      "        -0.2990, -0.8111,  0.0398, -0.0568, -0.4888, -0.1809, -0.2815, -0.2056,\n",
      "         0.4932, -0.0340, -0.5314, -0.2830, -1.4475, -0.1868,  0.0912,  0.1145,\n",
      "        -0.2817, -0.3356, -0.3166, -0.1089,  0.1011, -0.2374, -0.6496, -0.2680,\n",
      "         0.3510,  0.2635,  0.5940,  0.2674])\n",
      "tensor([-1.8970e-01,  5.0024e-02,  1.9084e-01, -4.9184e-02, -8.9737e-02,\n",
      "         2.1006e-01, -5.4952e-01,  9.8377e-02, -2.0135e-01,  3.4241e-01,\n",
      "        -9.2677e-02,  1.6100e-01, -1.3268e-01, -2.8160e-01,  1.8737e-01,\n",
      "        -4.2959e-01,  9.6039e-01,  1.3972e-01, -1.0781e+00,  4.0518e-01,\n",
      "         5.0539e-01, -5.5064e-01,  4.8440e-01,  3.8044e-01, -2.9055e-03,\n",
      "        -3.4942e-01, -9.9696e-02, -7.8368e-01,  1.0363e+00, -2.3140e-01,\n",
      "        -4.7121e-01,  5.7126e-01, -2.1454e-01,  3.5958e-01, -4.8319e-01,\n",
      "         1.0875e+00,  2.8524e-01,  1.2447e-01, -3.9248e-02, -7.6732e-02,\n",
      "        -7.6343e-01, -3.2409e-01, -5.7490e-01, -1.0893e+00, -4.1811e-01,\n",
      "         4.5120e-01,  1.2112e-01, -5.1367e-01, -1.3349e-01, -1.1378e+00,\n",
      "        -2.8768e-01,  1.6774e-01,  5.5804e-01,  1.5387e+00,  1.8859e-02,\n",
      "        -2.9721e+00, -2.4216e-01, -9.2495e-01,  2.1992e+00,  2.8234e-01,\n",
      "        -3.4780e-01,  5.1621e-01, -4.3387e-01,  3.6852e-01,  7.4573e-01,\n",
      "         7.2102e-02,  2.7931e-01,  9.2569e-01, -5.0336e-02, -8.5856e-01,\n",
      "        -1.3580e-01, -9.2551e-01, -3.3991e-01, -1.0394e+00, -6.7203e-02,\n",
      "        -2.1379e-01, -4.7690e-01,  2.1377e-01, -8.4008e-01,  5.2536e-02,\n",
      "         5.9298e-01,  2.9604e-01, -6.7644e-01,  1.3916e-01, -1.5504e+00,\n",
      "        -2.0765e-01,  7.2220e-01,  5.2056e-01, -7.6221e-02, -1.5194e-01,\n",
      "        -1.3134e-01,  5.8617e-02, -3.1869e-01, -6.1419e-01, -6.2393e-01,\n",
      "        -4.1548e-01, -3.8175e-02, -3.9804e-01,  4.7647e-01, -1.5983e-01])\n",
      "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
      "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
      "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
      "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
      "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
      "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
      "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
      "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
      "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
      "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
      "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
      "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
      "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([-1.2557,  0.6104,  0.5679, -0.9660, -0.4525, -0.0717,  0.5712, -0.3129,\n",
      "        -0.4381,  0.9062,  0.0696, -0.0531,  0.2503,  0.2784,  0.7772,  0.2633,\n",
      "         0.5687, -1.1171, -0.0783, -0.5132,  0.8071,  0.9921,  0.2275,  1.0847,\n",
      "         0.8829,  0.1722, -0.6869, -0.8647, -0.8000, -0.3474, -0.0441, -0.3044,\n",
      "         0.2341,  0.2859,  0.0605, -0.6548, -0.0397,  0.7488, -0.4647,  0.0630,\n",
      "        -0.1652, -1.2217, -0.0895, -0.8125,  0.2761, -0.1384, -0.7667, -0.9697,\n",
      "         0.8312, -0.7764, -1.3327, -0.2873, -0.0537,  1.1735, -1.1795, -2.7519,\n",
      "         0.4536,  1.1984,  2.8203,  0.0601,  0.3230,  0.1910,  0.3459, -0.4150,\n",
      "         0.1515,  0.3815,  1.6190,  0.9929, -0.8255, -0.0987,  0.7445, -0.3860,\n",
      "        -1.0004, -1.3050, -0.3127, -0.5763,  0.1409, -0.8027, -1.4714, -0.4801,\n",
      "         1.1993, -0.4856,  0.4050, -0.0329, -2.0510,  0.1828, -0.2723,  0.0433,\n",
      "         0.0668, -0.6283, -0.0585,  0.2825, -0.0833, -0.0222, -0.5591,  0.2459,\n",
      "         0.3605, -1.5877,  0.7698, -0.6500])\n",
      "tensor([-0.4296,  0.1767,  0.2919, -0.4379, -0.0848, -0.1197,  0.2996,  0.5321,\n",
      "        -0.6732, -0.4832, -0.1740, -0.1270, -0.3392,  0.5895,  0.8360,  0.0657,\n",
      "         0.0953,  0.1199, -0.0358,  0.5167, -0.1740, -0.1606,  0.8454,  0.1788,\n",
      "         0.7055,  0.0737,  0.1303, -0.6092,  0.2556,  0.3933, -0.8126, -0.0778,\n",
      "         0.0054, -0.6106,  0.9099, -0.0951,  0.0078,  0.3849, -0.1611, -0.0488,\n",
      "        -0.0422,  0.0646, -0.4960,  0.1466,  0.1186, -0.0331, -0.7811, -0.2897,\n",
      "        -0.0632,  0.1057,  0.2536,  0.0973, -0.0845,  0.3284,  0.4526, -1.6968,\n",
      "        -0.0670,  0.8395, -0.0646,  0.8311,  0.5942,  0.1560,  0.3395,  0.0683,\n",
      "         0.4182, -0.5090,  0.2990,  1.7071, -0.4791,  0.2970, -0.2985, -0.4081,\n",
      "        -0.7256, -0.6191,  0.0591,  0.3865, -0.2299, -0.6053, -0.1372,  0.3847,\n",
      "        -0.2589,  0.5773,  0.1741, -0.3610, -0.5416, -0.4179, -1.3240,  0.1041,\n",
      "         0.2874,  0.6908, -0.1353, -0.1599,  0.2861,  0.3781,  0.2335,  0.2351,\n",
      "         0.0747,  0.0089, -0.5285, -0.6004])\n",
      "tensor([-0.2212,  0.4534,  0.2661, -0.3326,  0.4518, -0.2019, -0.3313,  0.1246,\n",
      "         0.1820, -0.0583, -0.0246,  0.1112,  0.4757,  0.2342,  0.2044, -0.3419,\n",
      "        -0.0642,  0.5350,  0.8369,  0.0165, -0.1172, -0.2887, -0.2418, -0.1077,\n",
      "         0.6203,  0.2241, -0.1532,  0.1974, -0.4195, -0.6285, -0.5017, -0.2575,\n",
      "         0.1936, -0.1533,  0.4355, -0.1823,  0.0639, -0.2653, -0.0649, -0.3004,\n",
      "         0.3795, -0.0247, -0.4550, -0.4198, -0.4049,  0.0481, -0.2414,  0.2784,\n",
      "         0.9035, -0.2311,  0.0095,  0.1706,  0.2227,  0.1409, -0.3085,  0.0021,\n",
      "         0.0618,  0.5971, -0.6669, -0.2047, -0.3334,  0.7650, -0.2577,  0.0750,\n",
      "        -0.9154,  0.0026,  0.9991, -0.3367, -0.2243, -0.1756,  0.5828, -0.3406,\n",
      "         0.3583, -0.0912,  0.2634, -0.0446, -0.1553, -0.7286,  0.1214,  0.1291,\n",
      "        -0.0859,  0.1017,  0.2221,  0.2415,  0.7339, -0.3567, -0.2944, -0.0898,\n",
      "        -0.0700,  0.4370,  0.0233, -0.1013, -0.4114, -0.1729,  0.3329,  0.2516,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.1594, -0.0536, -0.4989,  0.6593])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some HIMYM sentence\n",
    "sentence = Sentence('Lets go to the mall, Today! - Robin Sparkles')\n",
    "# embed words in sentence \n",
    "document_embeddings.embed(sentence)\n",
    "for token in sentence:\n",
    "    print(token.embedding)\n",
    "# data type and size of embedding \n",
    "print(type(token.embedding))\n",
    "# storing size (length) *2 because there'll be concatenation of diff and mult vectors\n",
    "n = token.embedding.size()[0] * 2\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:55.692819Z",
     "start_time": "2019-04-20T00:14:55.687790Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateBinaryLabels(dataList, binaryOrNot):\n",
    "    if binaryOrNot:\n",
    "        dataLabels = []\n",
    "        for couple in dataList:\n",
    "            if couple['Label'] >= 0.6:\n",
    "                dataLabels.append(1)\n",
    "            elif couple['Label'] <= 0.2:\n",
    "                dataLabels.append(0)\n",
    "            else:\n",
    "                print(couple['Label'])\n",
    "        print(\"No of labels: \", len(dataLabels))\n",
    "    return dataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:55.710729Z",
     "start_time": "2019-04-20T00:14:55.695801Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateEmbeddings(someList):\n",
    "    from tqdm import tqdm\n",
    "    n = sentence.embedding.size()[0] * 2\n",
    "    s = torch.zeros(0,n)\n",
    "    for i in tqdm(range(len(someList))):\n",
    "\n",
    "        # retrieve the text sentence\n",
    "        sentence1 = Sentence(someList[i]['Sent_1'])\n",
    "        sentence2 = Sentence(someList[i]['Sent_2'])\n",
    "\n",
    "        # embed the sentences with our document embedding\n",
    "        document_embeddings.embed(sentence1)\n",
    "        document_embeddings.embed(sentence2)\n",
    "\n",
    "        # Calculate the element-wise product\n",
    "        productTensor = sentence1.get_embedding() * sentence2.get_embedding()\n",
    "        # Calculate the difference\n",
    "        absDiffTensor = torch.abs(sentence1.get_embedding() - sentence2.get_embedding())\n",
    "\n",
    "        # Add the concatenated vector as final embedding\n",
    "        embeddingVector = torch.cat([productTensor, absDiffTensor])\n",
    "        \n",
    "        # Adding Document embeddings to list #\n",
    "        s = torch.cat((s, embeddingVector.view(-1,n)),0)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:55.938206Z",
     "start_time": "2019-04-20T00:14:55.711725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of labels:  11530\n",
      "No of labels:  4142\n",
      "No of labels:  842\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainLabels = generateBinaryLabels(trainList, True)\n",
    "devLabels = generateBinaryLabels(devList, True)\n",
    "testLabels = generateBinaryLabels(testList, True)\n",
    "# pd.DataFrame(trainLabels)[0].value_counts()\n",
    "\n",
    "N = 5\n",
    "menMeans = (20, 35, 30, 35, 27)\n",
    "womenMeans = (25, 32, 34, 20, 25)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, menMeans, width)\n",
    "p2 = plt.bar(ind, womenMeans, width,\n",
    "             bottom=menMeans)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:14:55.946099Z",
     "start_time": "2019-04-20T00:14:55.939156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if int(trainList[4]['Label']) >= 0.6:\n",
    "    print(\"yeah\")\n",
    "trainLabels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.372312Z",
     "start_time": "2019-04-20T00:14:55.948093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of Dataset train.data 13063\n",
      "Debatable thus ignored tweet-combo count:  1533\n",
      "Final dataset size: 11530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████                                                              | 2131/11530 [00:14<01:10, 134.27it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 KiB (GPU 0; 4.00 GiB total capacity; 1.71 GiB already allocated; 0 bytes free; 597.38 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-90e1823805e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrainList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_List\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainEmbeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainEmbeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ef5bc236935a>\u001b[0m in \u001b[0;36mgenerateEmbeddings\u001b[1;34m(someList)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# embed the sentences with our document embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdocument_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdocument_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Calculate the element-wise product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\flair\\embeddings.py\u001b[0m in \u001b[0;36membed\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m   1722\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1724\u001b[1;33m         \u001b[0mrnn_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_lengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[1;32m--> 182\u001b[1;33m                            self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LSTM'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 KiB (GPU 0; 4.00 GiB total capacity; 1.71 GiB already allocated; 0 bytes free; 597.38 MiB cached)"
     ]
    }
   ],
   "source": [
    "trainList = make_List('train.data')\n",
    "trainEmbeddings = generateEmbeddings(trainList)\n",
    "print(trainEmbeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.374306Z",
     "start_time": "2019-04-20T00:14:45.224Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testList = make_List('test.data')\n",
    "testEmbeddings = generateEmbeddings(testList)\n",
    "print(testEmbeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.375322Z",
     "start_time": "2019-04-20T00:14:45.225Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "devList = make_List('dev.data')\n",
    "devEmbeddings = generateEmbeddings(devList)\n",
    "print(devEmbeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.376300Z",
     "start_time": "2019-04-20T00:14:45.227Z"
    }
   },
   "outputs": [],
   "source": [
    "binThresHold = 0.075\n",
    "def custom_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label().astype(np.int)\n",
    "    preds = (preds >= 0.075).astype(np.int)\n",
    "    return [('f1_score', f1_score(labels, preds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.377299Z",
     "start_time": "2019-04-20T00:14:45.229Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "x_train = trainEmbeddings.numpy()\n",
    "y_train = np.array(trainLabels).reshape(len(trainLabels), -1)\n",
    "x_valid = devEmbeddings.numpy()\n",
    "y_valid = np.array(devLabels).reshape(len(devLabels), -1)\n",
    "\n",
    "### XGBoost compatible data ###\n",
    "dtrain = xgb.DMatrix(x_train,y_train)\n",
    "dvalid = xgb.DMatrix(x_valid, label = y_valid)\n",
    "\n",
    "### defining parameters ###\n",
    "params = {\n",
    "          'colsample': 0.9,\n",
    "          'colsample_bytree': 0.5,\n",
    "          'eta': 0.1,\n",
    "          'max_depth': 8,\n",
    "          'min_child_weight': 6,\n",
    "          'objective': 'binary:logistic',\n",
    "          'subsample': 0.9\n",
    "          }\n",
    "\n",
    "### Training the model ###\n",
    "xgb_model = xgb.train(\n",
    "                      params,\n",
    "                      dtrain,\n",
    "                      feval= custom_eval,\n",
    "                      num_boost_round= 1000,\n",
    "                      maximize=True,\n",
    "                      evals=[(dvalid, \"Validation\")],\n",
    "                      early_stopping_rounds=30\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.377299Z",
     "start_time": "2019-04-20T00:14:45.232Z"
    }
   },
   "outputs": [],
   "source": [
    "### Reformatting test set for XGB ###\n",
    "dtest = xgb.DMatrix(devEmbeddings)\n",
    "\n",
    "### Predicting ###\n",
    "predict = xgb_model.predict(dtest) # predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.378296Z",
     "start_time": "2019-04-20T00:14:45.236Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict[198])\n",
    "print(devLabels[198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.379294Z",
     "start_time": "2019-04-20T00:14:45.240Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "y_pred = np.array([1 if (predict[i] >= binThresHold) else 0 for i in range(len(predict))])\n",
    "y_true = np.array(devLabels)\n",
    "score = precision_recall_fscore_support(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T00:15:10.380324Z",
     "start_time": "2019-04-20T00:14:45.242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████                                                              | 2131/11530 [00:30<01:10, 134.27it/s]"
     ]
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
