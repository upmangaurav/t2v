{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:10.657660Z",
     "start_time": "2019-04-30T12:28:10.349080Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dev.data',\n",
       " 'SemEval15DataFiles',\n",
       " 'test.data',\n",
       " 'test.label',\n",
       " 'train.data',\n",
       " 'tweetText.txt',\n",
       " 'tweetTextFromDevData',\n",
       " 'tweetTextFromDevData_parsed.txt',\n",
       " 'tweetTextFromTestData',\n",
       " 'tweetTextFromTestData_parsed.txt',\n",
       " 'tweetTextFromTrainData',\n",
       " 'tweetTextFromTrainData_parsed.txt',\n",
       " 'tweetText_parsed.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install flair\n",
    "# !pip install tqdm\n",
    "# !ls -lh\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(\"d:\\\\Thesis\\\\SemEval15\\\\SemEval-PIT2015-github\\\\data\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:39.290829Z",
     "start_time": "2019-04-30T12:28:10.659667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, DocumentRNNEmbeddings, \\\n",
    "Sentence, ELMoEmbeddings, BertEmbeddings, BytePairEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets load the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:41.782276Z",
     "start_time": "2019-04-30T12:28:39.292807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to download the data file ...\n",
      "Extracted downloaded data file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data.zip', 'dev.data', 'test.data', 'test.label', 'train.data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "baseDir = os.getcwd()\n",
    "dataDir = baseDir + os.sep + \"/SemEval15DataFiles/\"\n",
    "os.makedirs(dataDir, exist_ok=True)\n",
    "os.chdir(dataDir)\n",
    "\n",
    "url = 'https://github.com/upmangaurav/t2v/raw/master/data/data.zip'\n",
    "print('Beginning to download the data file ...')\n",
    "urllib.request.urlretrieve(url, dataDir + 'data.zip')\n",
    "\n",
    "zip_ref = zipfile.ZipFile('data.zip', 'r')\n",
    "zip_ref.extractall(dataDir)\n",
    "print('Extracted downloaded data file...')\n",
    "zip_ref.close()\n",
    "\n",
    "!ls -lh\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:41.794212Z",
     "start_time": "2019-04-30T12:28:41.784239Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_List(file):\n",
    "    debatableCount = 0\n",
    "    with open(file, 'r') as f:\n",
    "        td = f.readlines()\n",
    "\n",
    "    dataList = []\n",
    "    print(\"\\nSize of Dataset\", file, str(len(td)))\n",
    "    for item in td:\n",
    "        trainDict = {}\n",
    "        splitsie = item.split('\\t')\n",
    "\n",
    "        #For training and dev data:\n",
    "        if len(splitsie[4]) > 1:\n",
    "            #debatable if only 2 turkers voted similar\n",
    "            if splitsie[4][1] == '2':\n",
    "                debatableCount += 1\n",
    "                continue\n",
    "        #Convert Label such as (3, 2) to decimal value like 0.6\n",
    "            else: trainDict['Label'] = 0.2 * int(splitsie[4][1])\n",
    "\n",
    "        else: # Test data:\n",
    "            if splitsie[4] == '2':\n",
    "                debatableCount += 1\n",
    "                continue\n",
    "\n",
    "            else: trainDict['Label'] = 0.2 * int(splitsie[4])\n",
    "\n",
    "        \n",
    "        trainDict['Topic_Id'] = splitsie[0]\n",
    "        trainDict['Topic_Name'] = splitsie[1]\n",
    "        trainDict['Sent_1'] = splitsie[2]\n",
    "        trainDict['Sent_2'] = splitsie[3]\n",
    "\n",
    "        dataList.append(trainDict)\n",
    "    \n",
    "    print(\"Debatable thus ignored tweet-combo count: \", debatableCount)\n",
    "    print(\"Final dataset size:\", len(dataList))\n",
    "    return dataList "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:41.952820Z",
     "start_time": "2019-04-30T12:28:41.796207Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of Dataset train.data 13063\n",
      "Debatable thus ignored tweet-combo count:  1533\n",
      "Final dataset size: 11530\n",
      "\n",
      "Size of Dataset test.data 972\n",
      "Debatable thus ignored tweet-combo count:  130\n",
      "Final dataset size: 842\n",
      "\n",
      "Size of Dataset dev.data 4727\n",
      "Debatable thus ignored tweet-combo count:  585\n",
      "Final dataset size: 4142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'But my bro from the 757 EJ Manuel is the 1st QB gone'},\n",
       " {'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'Can believe EJ Manuel went as the 1st QB in the draft'},\n",
       " {'Label': 0.6000000000000001,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'EJ MANUEL IS THE 1ST QB what'},\n",
       " {'Label': 0.8,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'Manuel is the 1st QB to get drafted'},\n",
       " {'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'My boy EJ Manuel being the 1st QB picked'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainList = make_List('train.data')\n",
    "testList = make_List('test.data')\n",
    "devList = make_List('dev.data')\n",
    "trainList[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:42.507941Z",
     "start_time": "2019-04-30T12:28:41.956777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "# If need to run on CPU:\n",
    "import flair, torch\n",
    "flair.device = torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:42.522862Z",
     "start_time": "2019-04-30T12:28:42.509898Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def embeddingManager(word = True, flair = False, BERT = False, ELMO = False, bytePair = False, etype = 'pool', \\\n",
    "                    rnnType = 'GRU'):\n",
    "    '''\n",
    "    Parameters:\n",
    "    https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md\n",
    "    \n",
    "    :flair: Forward/Backward combos of multi, multi-fast, news, news-fast and mix\n",
    "    e.g. 'multi-forward'+'multi-backward', 'news-forward-fast'+'news-backward-fast' etc\n",
    "    \n",
    "    :word: glove, twitter, crawl etc\n",
    "    :BERT: 'bert-base-uncased', 'bert-large-uncased', 'bert-base-cased' and 'bert-large-cased'\n",
    "    :ELMO: 'small', 'medium' and 'original'\n",
    "    :etype: 'pool' or 'RNN'\n",
    "    :rnnType: 'GRU', 'LSTM',  'RNN_TANH' or 'RNN_RELU'\n",
    "    \n",
    "    '''\n",
    "\n",
    "    embeddings = []\n",
    "    \n",
    "    if word:\n",
    "        if word == True: # Default case\n",
    "            embeddings.append(WordEmbeddings('twitter'))\n",
    "        else:\n",
    "            embeddings.append(WordEmbeddings(word))\n",
    "\n",
    "    if bytePair:\n",
    "        embeddings.append(BytePairEmbeddings('en'))\n",
    "    \n",
    "    if flair:\n",
    "        if flair == True:\n",
    "            flair = 'mix' # Default flavour is mix-forward and mix-backward\n",
    "        \n",
    "        flair = [i.lower() for i in flair.split('-') if i.lower() != 'forward' and i.lower() != 'backward']\n",
    "        if len(flair) > 1:\n",
    "            embeddings.append(FlairEmbeddings(flair[0] + '-forward-' + (flair[1])))\n",
    "            embeddings.append(FlairEmbeddings(flair[0] + '-backward-' + (flair[1])))\n",
    "        else:\n",
    "            embeddings.append(FlairEmbeddings(flair[0] + '-forward'))\n",
    "            embeddings.append(FlairEmbeddings(flair[0] + '-backward'))\n",
    "            \n",
    "    if BERT:\n",
    "        if BERT == True: # Default flavour\n",
    "            embeddings.append(BertEmbeddings('bert-base-cased'))\n",
    "        else: \n",
    "            embeddings.append(BertEmbeddings(BERT))\n",
    "    if ELMO:\n",
    "        if ELMO == True: # Default flavour\n",
    "            embeddings.append(ELMoEmbeddings())\n",
    "        else:\n",
    "            embeddings.append(ELMoEmbeddings(ELMO))\n",
    "    #\n",
    "    \n",
    "    if etype == 'RNN':\n",
    "        document_embeddings = DocumentRNNEmbeddings(embeddings, rnn_type = rnnType, hidden_size = 400)\n",
    "    else:\n",
    "        document_embeddings = DocumentPoolEmbeddings(embeddings)        \n",
    "    return document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:46.876739Z",
     "start_time": "2019-04-30T12:28:42.526854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3154e-01,  1.0971e+00,  5.1758e-01, -2.2897e-01,  1.8733e-02,\n",
      "         4.3993e-02,  9.0039e-01,  5.1511e-01,  9.4340e-02, -2.3853e-01,\n",
      "        -2.1572e-01,  8.1121e-02, -4.1701e+00,  5.1344e-01, -5.4916e-01,\n",
      "        -7.7124e-01, -1.6007e-01,  2.2152e-01, -1.2646e-01, -3.5542e-01,\n",
      "        -4.3379e-02, -1.0977e-01, -3.2559e-01,  8.4611e-02, -4.5952e-01,\n",
      "         7.6447e-02,  1.5328e-01,  5.1227e-01,  1.5058e-01, -4.8644e-01,\n",
      "        -4.7686e-01, -1.7577e-01, -7.8092e-02,  3.9166e-01,  2.7987e-01,\n",
      "         2.5278e-01,  2.1930e-01, -2.9568e-01,  1.2269e-01,  8.1838e-02,\n",
      "        -3.4231e-01, -1.2624e-01, -2.3840e-01,  4.7515e-03,  2.1875e-01,\n",
      "        -1.1369e-01, -1.1442e-01,  3.6679e-02,  8.6251e-03,  4.5520e-01,\n",
      "        -4.4669e-01, -5.9066e-01,  8.7064e-01,  9.7721e-02,  5.0219e-01,\n",
      "        -1.3593e-01, -3.4096e-01,  5.0584e-01,  2.3911e-01, -1.1789e-01,\n",
      "         6.9777e-01, -4.6228e-02, -2.0501e-01,  2.3928e-01, -1.7156e-01,\n",
      "        -3.9095e-01, -3.5170e-03,  5.2304e-01, -3.0086e-01, -1.6764e-01,\n",
      "         3.5876e-01,  1.5237e-01, -2.0810e-01,  6.7461e-01, -4.7898e-01,\n",
      "         3.5353e-01,  4.7495e-01,  3.7038e-01,  3.7895e-01,  2.6139e-01,\n",
      "         1.3112e+00,  2.8209e-01, -2.7625e-01, -4.7028e-01,  6.6873e-01,\n",
      "        -1.3269e-01, -6.9158e-01, -1.9058e-01, -4.2551e-01, -1.9306e-01,\n",
      "        -7.7017e-01,  1.0367e-01, -6.0128e-01, -3.6043e-01, -5.6272e-02,\n",
      "        -6.8979e-02,  1.5909e-01,  9.6815e-01,  2.0241e-01, -4.2647e-01])\n",
      "tensor([-1.5780e-01,  4.2632e-01,  3.6328e-01, -5.0215e-01,  2.0830e-02,\n",
      "         4.5664e-01,  5.2811e-01,  6.7733e-01, -2.3145e-02,  1.3908e-01,\n",
      "        -2.1923e-01,  5.3675e-02, -5.0171e+00,  2.7719e-01, -6.9760e-01,\n",
      "        -6.7883e-01, -4.8144e-02,  1.9238e-01, -5.2252e-01, -2.1818e-02,\n",
      "        -3.4967e-02, -3.8485e-01, -2.3326e-01, -3.6813e-01, -7.9426e-02,\n",
      "        -7.2141e-01,  5.8191e-01,  1.2995e-01,  4.0925e-01, -4.0014e-01,\n",
      "        -2.5543e-02,  9.6698e-02, -1.0112e-01,  2.7941e-01,  5.0813e-01,\n",
      "         5.0899e-01,  3.2202e-01, -3.4812e-01,  5.5787e-01,  9.3483e-01,\n",
      "        -7.5861e-01,  1.5875e-03, -3.2801e-01, -2.9363e-01,  5.3360e-01,\n",
      "         2.9135e-01,  1.4157e-01, -3.9550e-01, -6.5171e-02,  1.9243e-01,\n",
      "        -2.4080e-01, -2.9564e-01,  7.6354e-01,  3.9559e-01, -3.4742e-02,\n",
      "        -2.7686e-01, -2.3839e-01,  5.9092e-02,  1.7989e-01,  3.6655e-01,\n",
      "         4.2234e-01,  2.9162e-01, -1.7306e-01, -2.2426e-01, -2.6415e-01,\n",
      "        -4.7953e-01, -5.7696e-01,  1.3031e-01, -4.5968e-01,  3.8020e-01,\n",
      "         2.3406e-01,  5.1361e-01,  2.3821e-01,  2.3289e-01, -6.7490e-01,\n",
      "         5.2126e-02,  8.6672e-01,  1.5092e-01,  8.1800e-01, -3.9227e-01,\n",
      "         1.3881e+00,  3.2658e-01, -6.8364e-02, -6.1969e-01,  6.6891e-01,\n",
      "         4.5530e-01, -8.4101e-01, -1.7943e-01, -8.5915e-02, -1.8906e-01,\n",
      "        -6.3392e-01, -8.3477e-02, -1.1631e-01, -2.0255e-01, -1.9418e-01,\n",
      "         1.3127e-01, -1.5019e-01,  2.5422e-01,  5.9067e-02, -8.8419e-02])\n",
      "tensor([ 8.5375e-01,  2.2774e-01,  6.9474e-01, -3.1440e-02,  1.9541e-01,\n",
      "        -8.2815e-02,  2.3637e-01, -8.2565e-02,  3.0448e-01, -5.9252e-01,\n",
      "        -7.6921e-02, -5.5073e-01, -6.0970e+00, -4.0976e-02, -3.5000e-01,\n",
      "        -6.9981e-01, -4.8875e-01,  2.0849e-01, -3.4315e-01, -6.5268e-01,\n",
      "        -2.7352e-01,  2.1734e-01, -4.6375e-01,  1.7651e-01,  2.3839e-01,\n",
      "        -9.6789e-01,  3.8883e-01,  3.7856e-01,  7.7049e-01,  5.3860e-02,\n",
      "         7.1532e-01,  1.4966e-01, -3.1613e-02, -3.2980e-01,  2.1020e-01,\n",
      "        -7.7201e-02, -1.7806e-01, -4.5322e-01, -5.9346e-01,  6.2375e-02,\n",
      "        -1.2993e+00,  4.6054e-01,  2.4701e-01, -1.8502e-01,  5.1299e-01,\n",
      "         1.8830e-01, -2.5535e-01, -4.4128e-01, -3.4789e-01, -4.1458e-01,\n",
      "        -1.3016e-01, -2.3222e-01,  6.7577e-01,  1.0056e+00, -3.3450e-01,\n",
      "        -5.9970e-02,  6.3921e-03,  5.0980e-01, -4.7332e-01,  2.4197e-01,\n",
      "         6.6505e-01,  4.1811e-01, -6.1257e-01, -5.3915e-01,  2.5595e-01,\n",
      "        -1.0160e-01, -8.6986e-01, -2.8008e-01, -5.6193e-01,  5.2878e-01,\n",
      "         7.5782e-02, -2.8897e-01,  2.0710e-01,  7.0829e-01,  9.2346e-02,\n",
      "         1.7942e-02,  7.3071e-01, -4.4274e-01,  4.3053e-01, -1.2142e-01,\n",
      "         1.2525e+00,  6.3398e-01,  3.7943e-03,  3.5126e-01,  3.0714e-01,\n",
      "         1.2979e-01, -1.0944e-01,  1.4636e-01,  2.8364e-01, -1.3353e-01,\n",
      "        -3.5083e-01,  3.0999e-01,  3.0578e-01, -3.2253e-01,  1.1302e-01,\n",
      "        -6.7793e-01,  6.8984e-02, -1.9030e-02,  1.6150e-01,  2.7763e-01])\n",
      "tensor([ 9.5152e-02,  3.7024e-01,  5.4291e-01,  1.9621e-01,  4.8205e-02,\n",
      "         3.2033e-01, -5.9638e-01,  1.5868e-02, -1.2989e-01, -6.3028e-01,\n",
      "         8.1944e-02,  2.4164e-01, -6.0990e+00, -6.8557e-01,  5.0354e-01,\n",
      "        -3.4089e-02,  1.1705e-01, -7.7403e-03, -8.6512e-02,  4.3617e-01,\n",
      "        -4.3982e-01,  2.6125e-01, -4.0348e-02, -1.9194e-01,  8.3204e-02,\n",
      "        -5.8246e-01, -3.1923e-02,  1.2630e-01,  4.0120e-01,  6.8906e-02,\n",
      "        -1.0517e-01, -2.0804e-01, -4.2554e-01,  4.7799e-01,  3.4651e-01,\n",
      "         2.4057e-01,  5.0244e-02, -7.2587e-02, -2.4347e-03, -5.0342e-01,\n",
      "        -1.0601e+00, -3.1586e-01, -3.2457e-02, -7.6317e-02,  7.9045e-01,\n",
      "         8.6367e-02, -1.9632e-01,  5.7566e-02,  8.4129e-01, -4.2020e-01,\n",
      "        -1.1335e-03, -8.5632e-02,  6.1910e-02,  2.1423e-01, -1.0356e-01,\n",
      "        -3.6946e-02, -2.6005e-01, -3.5657e-01,  5.4321e-02,  3.0875e-02,\n",
      "         1.4092e-01, -9.1998e-02, -4.1841e-01, -3.1135e-01, -1.4937e-01,\n",
      "        -2.2699e-04, -3.3454e-01, -1.4848e-01, -1.1944e-01, -2.7174e-01,\n",
      "         3.1320e-01, -1.0998e-01, -4.7524e-01,  1.4056e-01,  3.9641e-01,\n",
      "        -4.9413e-02, -4.2601e-01, -2.3576e-01,  6.1482e-02, -3.5313e-02,\n",
      "         2.4161e+00,  2.8979e-01,  3.8882e-01,  3.6779e-01,  2.0685e-01,\n",
      "         1.3992e-01, -4.2459e-01,  4.4590e-01,  2.6234e-01, -4.4834e-01,\n",
      "         3.7196e-03, -2.2521e-01,  1.4764e-01, -3.6417e-01, -1.8493e-01,\n",
      "         2.2282e-01,  4.7626e-01, -5.1083e-01,  4.6877e-01,  3.4882e-01])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([ 0.0096, -0.1357,  0.0996,  0.4354, -0.5885,  0.4220,  0.1759, -0.3107,\n",
      "        -0.1024,  0.1777,  0.2691, -0.3781, -2.3980, -0.6966,  0.4378, -0.8354,\n",
      "         0.2875,  0.2228,  0.4603, -0.1256, -0.2674, -0.2731,  0.5072,  0.6911,\n",
      "         0.9052, -1.6874, -0.4736,  0.5072,  0.7514,  0.3236, -0.4467, -0.5733,\n",
      "        -0.9627,  0.1673,  1.4390,  0.4709, -0.3764,  0.3468, -0.5931, -0.8395,\n",
      "        -1.4315, -0.2608, -0.1282,  0.5596,  0.4823, -0.6355, -0.4324,  0.0228,\n",
      "         0.0557, -0.0033, -0.7423, -0.6026,  0.1093,  0.5673,  0.1332, -0.0157,\n",
      "        -0.1209,  0.0645, -0.4307,  0.7071, -0.1715, -0.4146, -0.2464, -1.1750,\n",
      "        -0.0560, -1.0602, -0.2494, -0.5296,  0.8066,  0.2813,  0.5752,  0.1184,\n",
      "         0.5076, -0.2420,  0.1852, -1.2742, -0.0118,  0.1983,  0.0157, -0.5405,\n",
      "         0.6627, -0.0808, -0.0296, -0.1114,  0.0565, -0.3881, -0.1872,  1.3549,\n",
      "         0.5731, -0.1303, -0.5120, -0.2935,  0.1490,  0.0888,  0.3196,  0.0488,\n",
      "         0.0777, -0.6242,  0.4041,  0.2222])\n",
      "tensor([ 0.1608, -0.3233,  0.5141, -0.4331, -0.9991, -0.4363, -0.2070,  0.0225,\n",
      "        -0.5030, -0.3503,  0.5504,  0.8376, -2.1954, -0.3798, -0.1946,  0.1862,\n",
      "         0.4661,  0.5565,  0.1689,  0.6869,  0.3345, -0.2945, -0.2831, -0.2049,\n",
      "         0.0142, -0.7648,  0.4876,  0.4321, -0.3964, -0.7916, -0.1403,  0.2564,\n",
      "        -0.7797, -0.7625,  0.4187,  0.2983, -0.4657,  0.1486,  0.1913,  0.0527,\n",
      "        -0.3268, -0.6160, -0.0824,  0.0636, -0.3421, -0.2931,  0.3789,  0.0378,\n",
      "         0.1776,  0.3383, -0.1101, -0.0336,  0.2114,  0.2057, -0.0893,  0.0850,\n",
      "         0.2421,  0.3820, -0.1286,  0.1926, -0.2384,  0.1619, -0.1089, -0.1319,\n",
      "        -0.1325,  0.0079, -0.3524, -0.4650, -0.0644,  0.2206,  0.2766, -0.1961,\n",
      "         0.6944,  0.4895,  0.1867, -0.8284, -0.0580, -0.1195, -0.5389,  0.6186,\n",
      "         0.7809,  0.0839,  0.2455,  0.1916, -0.3866, -0.6876, -0.0427, -0.3035,\n",
      "        -0.8160, -0.2496,  0.5933, -0.2697, -0.7265,  0.1411, -0.0691,  1.3272,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.5138,  0.5314, -0.2021, -0.2730])\n",
      "tensor([-1.3099, -0.1769,  0.1080,  0.8569, -0.2217, -0.2068,  0.2923, -0.3160,\n",
      "        -0.4200, -0.1439,  0.1563,  0.6569, -1.3290, -0.4615, -0.1983,  0.2484,\n",
      "        -0.2095,  0.0353,  0.1969,  0.7464,  0.4017, -0.6322, -0.4889, -0.3780,\n",
      "         0.3501,  0.9902, -0.2069,  1.3713,  0.4787,  0.2419, -0.6912,  1.1045,\n",
      "         0.8004, -0.1772, -0.7457,  0.0867, -0.0292,  0.0832,  0.1196,  0.8938,\n",
      "         0.2247, -0.7047, -0.1133, -0.1234,  0.3906, -0.6963,  1.0290, -0.1618,\n",
      "        -0.3658,  0.6510, -0.3188, -0.2860,  0.4327, -0.0945,  0.5069,  0.4856,\n",
      "         0.6561, -0.0421, -0.5703,  0.2497,  0.0686,  0.0124,  0.3497, -0.0073,\n",
      "        -0.9093,  0.4600,  0.0460,  0.0421,  0.6206,  0.2813,  0.4306, -0.4552,\n",
      "        -0.3384, -0.4234, -0.0445,  0.3325, -0.6972, -0.4817, -0.1675,  0.3064,\n",
      "         1.0281, -0.1316, -0.2594, -0.1959, -0.5050, -0.1980,  0.7785, -0.6423,\n",
      "        -0.8292, -0.8981,  0.6367,  0.3663, -1.1765,  0.2033, -0.6912, -0.6035,\n",
      "         0.2941, -0.2732, -0.2753,  0.3206])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some HIMYM sentence\n",
    "sentence = Sentence('Lets go to the mall, Today! - Robin Sparkles')\n",
    "# embed words in sentence \n",
    "embeddingManager().embed(sentence)\n",
    "for token in sentence:\n",
    "    print(token.embedding)\n",
    "# data type and size of embedding \n",
    "print(type(token.embedding))\n",
    "# storing size (length) *2 because there'll be concatenation of diff and mult vectors\n",
    "n = token.embedding.size()[0] * 2\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:46.890718Z",
     "start_time": "2019-04-30T12:28:46.880750Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateBinaryLabels(dataList, binaryOrNot):\n",
    "    if binaryOrNot:\n",
    "        dataLabels = []\n",
    "        for couple in dataList:\n",
    "            if couple['Label'] >= 0.6:\n",
    "                dataLabels.append(1)\n",
    "            elif couple['Label'] <= 0.2:\n",
    "                dataLabels.append(0)\n",
    "            else:\n",
    "                print(couple['Label'])\n",
    "        print(\"No of labels: \", len(dataLabels))\n",
    "    return dataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:46.916631Z",
     "start_time": "2019-04-30T12:28:46.891698Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateEmbeddings(someList, **kwargs):\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    document_embeddings = embeddingManager(**kwargs)\n",
    "    \n",
    "    sentence = Sentence('Lets go to the mall, Today! - Robin Sparkles')\n",
    "\n",
    "    # embed words in sentence \n",
    "    document_embeddings.embed(sentence)\n",
    "\n",
    "    n = sentence.embedding.size()[0] * 2\n",
    "    s = torch.zeros(0,n)\n",
    "    print(s.size())\n",
    "    print(n)\n",
    "    for i in tqdm(range(len(someList))):\n",
    "\n",
    "        # retrieve the text sentence\n",
    "        sentence1 = Sentence(someList[i]['Sent_1'])\n",
    "        sentence2 = Sentence(someList[i]['Sent_2'])\n",
    "\n",
    "        # embed the sentences with our document embedding\n",
    "        document_embeddings.embed(sentence1)\n",
    "        document_embeddings.embed(sentence2)\n",
    "\n",
    "        # Calculate the element-wise product\n",
    "        productTensor = sentence1.get_embedding() * sentence2.get_embedding()\n",
    "        # Calculate the difference\n",
    "        absDiffTensor = torch.abs(sentence1.get_embedding() - sentence2.get_embedding())\n",
    "\n",
    "        # Add the concatenated vector as final embedding\n",
    "        embeddingVector = torch.cat([productTensor, absDiffTensor])\n",
    "        \n",
    "        # Adding Document embeddings to list #\n",
    "        s = torch.cat((s, embeddingVector.view(-1,n)),0)\n",
    "        \n",
    "#         torch.cuda.empty_cache()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:46.933596Z",
     "start_time": "2019-04-30T12:28:46.917629Z"
    }
   },
   "outputs": [],
   "source": [
    "def masterFunction(dataList, binaryOrNot, **kwargs):\n",
    "    rawList = make_List(dataList)\n",
    "    labelList = generateBinaryLabels(rawList, binaryOrNot)\n",
    "    embeddingList = generateEmbeddings(rawList, **kwargs)\n",
    "    \n",
    "    # A litttle reformatting to make the data and labels model-friendly\n",
    "    labelList = np.array(labelList).reshape(len(labelList), -1)\n",
    "    embeddingList = embeddingList.detach().numpy()\n",
    "    \n",
    "    return embeddingList, labelList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T22:34:22.665554Z",
     "start_time": "2019-04-29T22:34:22.661565Z"
    }
   },
   "source": [
    "### embeddingManager function Parameters for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    :flair: multi, multi-fast, news, news-fast or mix\n",
    "    To generate Forward/Backward combos e.g. 'multi-forward'+'multi-backward', 'news-forward-fast'+'news-backward-fast' etc\n",
    "\n",
    "    :word: glove, twitter, crawl etc\n",
    "    :BERT: 'bert-base-uncased', 'bert-large-uncased', 'bert-base-cased' and 'bert-large-cased'\n",
    "    :ELMO: 'small', 'medium' and 'original'\n",
    "    :etype: 'pool' or 'RNN'\n",
    "    :rnnType: 'GRU', 'LSTM',  'RNN_TANH' or 'RNN_RELU'\n",
    "\n",
    "    reference: https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T12:28:46.951575Z",
     "start_time": "2019-04-30T12:28:46.934616Z"
    }
   },
   "outputs": [],
   "source": [
    "binThresHold = 0.075\n",
    "def custom_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label().astype(np.int)\n",
    "    preds = (preds >= binThresHold).astype(np.int)\n",
    "    return [('f1_score', f1_score(labels, preds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T15:19:12.362824Z",
     "start_time": "2019-04-30T12:28:46.953533Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of Dataset train.data 13063\n",
      "Debatable thus ignored tweet-combo count:  1533\n",
      "Final dataset size: 11530\n",
      "No of labels:  11530\n",
      "torch.Size([0, 512])\n",
      "512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████▍               | 9066/11530 [2:50:11<1:01:47,  1.50s/it]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-73f2a8528a43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasterFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0membeddingsArgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasterFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dev.data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0membeddingsArgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-942067434fa7>\u001b[0m in \u001b[0;36mmasterFunction\u001b[1;34m(dataList, binaryOrNot, **kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mrawList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_List\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlabelList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateBinaryLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinaryOrNot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0membeddingList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# A litttle reformatting to make the data and labels model-friendly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-12029a81dd72>\u001b[0m in \u001b[0;36mgenerateEmbeddings\u001b[1;34m(someList, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# Adding Document embeddings to list #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddingVector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m#         torch.cuda.empty_cache()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Only For parameter reference:\n",
    "embeddingManager()\n",
    "\n",
    "embeddingsArgs = {\n",
    "    'flair':'mix',\n",
    "      'etype':'RNN',\n",
    "#       'rnnType': 'LSTM',\n",
    "}\n",
    "\n",
    "x_train, y_train = masterFunction('train.data', True, **embeddingsArgs)\n",
    "x_valid, y_valid = masterFunction('dev.data', True, **embeddingsArgs)\n",
    "\n",
    "### XGBoost compatible data ###\n",
    "dtrain = xgb.DMatrix(x_train,y_train)\n",
    "dvalid = xgb.DMatrix(x_valid, label = y_valid)\n",
    "\n",
    "### defining parameters ###\n",
    "params = {\n",
    "          'colsample': 0.9,\n",
    "          'colsample_bytree': 0.5,\n",
    "          'eta': 0.1,\n",
    "          'max_depth': 8,\n",
    "          'min_child_weight': 6,\n",
    "          'objective': 'binary:logistic',\n",
    "          'subsample': 0.9\n",
    "          }\n",
    "\n",
    "### Training the model ###\n",
    "xgb_model = xgb.train(\n",
    "                      params,\n",
    "                      dtrain,\n",
    "                      feval= custom_eval,\n",
    "                      num_boost_round= 1000,\n",
    "                      maximize=True,\n",
    "                      evals=[(dvalid, \"Validation\")],\n",
    "                      early_stopping_rounds=100\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T15:19:12.442688Z",
     "start_time": "2019-04-30T12:28:10.379Z"
    }
   },
   "outputs": [],
   "source": [
    "### Reformatting test set for XGB ###\n",
    "x_test, y_test = masterFunction('test.data', True, **embeddingsArgs)\n",
    "\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "### Predicting ###\n",
    "predict = xgb_model.predict(dtest) # predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T15:19:12.446679Z",
     "start_time": "2019-04-30T12:28:10.382Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict[198])\n",
    "print(y_test[198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T15:19:12.453275Z",
     "start_time": "2019-04-30T12:28:10.385Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "y_pred = np.array([1 if (predict[i] >= binThresHold) else 0 for i in range(len(predict))])\n",
    "y_true = np.array(y_test)\n",
    "score = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
