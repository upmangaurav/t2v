{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:07.517358Z",
     "start_time": "2019-05-02T23:34:07.506414Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dev.data',\n",
       " 'SemEval15DataFiles',\n",
       " 'test.data',\n",
       " 'test.label',\n",
       " 'train.data',\n",
       " 'tweetText.txt',\n",
       " 'tweetTextFromDevData',\n",
       " 'tweetTextFromDevData_parsed.txt',\n",
       " 'tweetTextFromTestData',\n",
       " 'tweetTextFromTestData_parsed.txt',\n",
       " 'tweetTextFromTrainData',\n",
       " 'tweetTextFromTrainData_parsed.txt',\n",
       " 'tweetText_parsed.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install flair\n",
    "# !pip install tqdm\n",
    "# !ls -lh\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(\"d:\\\\Thesis\\\\SemEval15\\\\SemEval-PIT2015-github\\\\data\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:08.997183Z",
     "start_time": "2019-05-02T23:34:07.519346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, DocumentRNNEmbeddings, \\\n",
    "Sentence, ELMoEmbeddings, BertEmbeddings, BytePairEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets load the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.517995Z",
     "start_time": "2019-05-02T23:34:08.999161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to download the data file ...\n",
      "Extracted downloaded data file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data.zip', 'dev.data', 'test.data', 'test.label', 'train.data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "baseDir = os.getcwd()\n",
    "dataDir = baseDir + os.sep + \"/SemEval15DataFiles/\"\n",
    "os.makedirs(dataDir, exist_ok=True)\n",
    "os.chdir(dataDir)\n",
    "\n",
    "url = 'https://github.com/upmangaurav/t2v/raw/master/data/data.zip'\n",
    "print('Beginning to download the data file ...')\n",
    "urllib.request.urlretrieve(url, dataDir + 'data.zip')\n",
    "\n",
    "zip_ref = zipfile.ZipFile('data.zip', 'r')\n",
    "zip_ref.extractall(dataDir)\n",
    "print('Extracted downloaded data file...')\n",
    "zip_ref.close()\n",
    "\n",
    "!ls -lh\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.527968Z",
     "start_time": "2019-05-02T23:34:12.519958Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_List(file):\n",
    "    debatableCount = 0\n",
    "    with open(file, 'r') as f:\n",
    "        td = f.readlines()\n",
    "\n",
    "    dataList = []\n",
    "    print(\"\\nSize of Dataset\", file, str(len(td)))\n",
    "    for item in td:\n",
    "        trainDict = {}\n",
    "        splitsie = item.split('\\t')\n",
    "\n",
    "        #For training and dev data:\n",
    "        if len(splitsie[4]) > 1:\n",
    "            #debatable if only 2 turkers voted similar\n",
    "            if splitsie[4][1] == '2':\n",
    "                debatableCount += 1\n",
    "                continue\n",
    "        #Convert Label such as (3, 2) to decimal value like 0.6\n",
    "            else: trainDict['Label'] = 0.2 * int(splitsie[4][1])\n",
    "\n",
    "        else: # Test data:\n",
    "            if splitsie[4] == '2':\n",
    "                debatableCount += 1\n",
    "                continue\n",
    "\n",
    "            else: trainDict['Label'] = 0.2 * int(splitsie[4])\n",
    "\n",
    "        \n",
    "        trainDict['Topic_Id'] = splitsie[0]\n",
    "        trainDict['Topic_Name'] = splitsie[1]\n",
    "        trainDict['Sent_1'] = splitsie[2]\n",
    "        trainDict['Sent_2'] = splitsie[3]\n",
    "\n",
    "        dataList.append(trainDict)\n",
    "    \n",
    "    print(\"Debatable thus ignored tweet-combo count: \", debatableCount)\n",
    "    print(\"Final dataset size:\", len(dataList))\n",
    "    return dataList "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.697499Z",
     "start_time": "2019-05-02T23:34:12.528935Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of Dataset train.data 13063\n",
      "Debatable thus ignored tweet-combo count:  1533\n",
      "Final dataset size: 11530\n",
      "\n",
      "Size of Dataset test.data 972\n",
      "Debatable thus ignored tweet-combo count:  130\n",
      "Final dataset size: 842\n",
      "\n",
      "Size of Dataset dev.data 4727\n",
      "Debatable thus ignored tweet-combo count:  585\n",
      "Final dataset size: 4142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'But my bro from the 757 EJ Manuel is the 1st QB gone'},\n",
       " {'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'Can believe EJ Manuel went as the 1st QB in the draft'},\n",
       " {'Label': 0.6000000000000001,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'EJ MANUEL IS THE 1ST QB what'},\n",
       " {'Label': 0.8,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'Manuel is the 1st QB to get drafted'},\n",
       " {'Label': 1.0,\n",
       "  'Topic_Id': '4',\n",
       "  'Topic_Name': '1st QB',\n",
       "  'Sent_1': 'EJ Manuel the 1st QB to go in this draft',\n",
       "  'Sent_2': 'My boy EJ Manuel being the 1st QB picked'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainList = make_List('train.data')\n",
    "testList = make_List('test.data')\n",
    "devList = make_List('dev.data')\n",
    "trainList[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.826279Z",
     "start_time": "2019-05-02T23:34:12.700477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050 Ti'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "# If need to run on CPU:\n",
    "# import flair, torch\n",
    "# flair.device = torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.839216Z",
     "start_time": "2019-05-02T23:34:12.828272Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def embeddingManager(word = True, flair = False, BERT = False, ELMO = False, bytePair = False, etype = 'pool', \\\n",
    "                    rnnType = 'GRU'):\n",
    "    '''\n",
    "    Parameters:\n",
    "    https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md\n",
    "    \n",
    "    :flair: Forward/Backward combos of multi, multi-fast, news, news-fast and mix\n",
    "    e.g. 'multi-forward'+'multi-backward', 'news-forward-fast'+'news-backward-fast' etc\n",
    "    \n",
    "    :word: glove, twitter, crawl etc\n",
    "    :BERT: 'bert-base-uncased', 'bert-large-uncased', 'bert-base-cased' and 'bert-large-cased'\n",
    "    :ELMO: 'small', 'medium' and 'original'\n",
    "    :etype: 'pool' or 'RNN'\n",
    "    :rnnType: 'GRU', 'LSTM',  'RNN_TANH' or 'RNN_RELU'\n",
    "    \n",
    "    '''\n",
    "\n",
    "    embeddings = []\n",
    "    \n",
    "    if word:\n",
    "        print(\"word called up!!\")\n",
    "        if word == True: # Default case\n",
    "            embeddings.append(WordEmbeddings('twitter'))\n",
    "        else:\n",
    "            embeddings.append(WordEmbeddings(word))\n",
    "\n",
    "    if bytePair:\n",
    "        embeddings.append(BytePairEmbeddings('en'))\n",
    "    \n",
    "    if flair:\n",
    "        if flair == True:\n",
    "            print(\"Flair called up!!\")\n",
    "            flair = 'mix' # Default flavour is mix-forward and mix-backward\n",
    "        \n",
    "        flair = [i.lower() for i in flair.split('-') if i.lower() != 'forward' and i.lower() != 'backward']\n",
    "        if len(flair) > 1:\n",
    "            embeddings.append(FlairEmbeddings(flair[0] + '-forward-' + (flair[1])))\n",
    "            embeddings.append(FlairEmbeddings(flair[0] + '-backward-' + (flair[1])))\n",
    "        else:\n",
    "            embeddings.append(FlairEmbeddings(flair[0] + '-forward'))\n",
    "            embeddings.append(FlairEmbeddings(flair[0] + '-backward'))\n",
    "            \n",
    "    if BERT:\n",
    "        if BERT == True: # Default flavour\n",
    "            print(\"Bert called up!!\")\n",
    "            embeddings.append(BertEmbeddings('bert-base-cased'))\n",
    "        else: \n",
    "            embeddings.append(BertEmbeddings(BERT))\n",
    "    if ELMO:\n",
    "        if ELMO == True: # Default flavour\n",
    "            embeddings.append(ELMoEmbeddings())\n",
    "        else:\n",
    "            embeddings.append(ELMoEmbeddings(ELMO))\n",
    "    #\n",
    "    \n",
    "    if etype == 'RNN':\n",
    "        document_embeddings = DocumentRNNEmbeddings(embeddings, rnn_type = rnnType, hidden_size = 400)\n",
    "    else:\n",
    "        document_embeddings = DocumentPoolEmbeddings(embeddings)        \n",
    "    return document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.867176Z",
     "start_time": "2019-05-02T23:34:12.842209Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Some HIMYM sentence\n",
    "# sentence = Sentence('Lets go to the mall, Today! - Robin Sparkles')\n",
    "# # embed words in sentence \n",
    "# embeddingManager().embed(sentence)\n",
    "# for token in sentence:\n",
    "#     print(token.embedding)\n",
    "# # data type and size of embedding \n",
    "# print(type(token.embedding))\n",
    "# # storing size (length) *2 because there'll be concatenation of diff and mult vectors\n",
    "# n = token.embedding.size()[0] * 2\n",
    "# n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.895922Z",
     "start_time": "2019-05-02T23:34:12.870134Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateBinaryLabels(dataList, binaryOrNot):\n",
    "    if binaryOrNot:\n",
    "        dataLabels = []\n",
    "        for couple in dataList:\n",
    "            if couple['Label'] >= 0.6:\n",
    "                dataLabels.append(1)\n",
    "            elif couple['Label'] <= 0.2:\n",
    "                dataLabels.append(0)\n",
    "            else:\n",
    "                print(couple['Label'])\n",
    "        print(\"No of labels: \", len(dataLabels))\n",
    "    return dataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.917471Z",
     "start_time": "2019-05-02T23:34:12.898908Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateEmbeddings(someList, **kwargs):\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    document_embeddings = embeddingManager(**kwargs)\n",
    "    \n",
    "    sentence = Sentence('Lets go to the mall, Today! - Robin Sparkles')\n",
    "\n",
    "    # embed words in sentence \n",
    "    document_embeddings.embed(sentence)\n",
    "\n",
    "    n = sentence.embedding.size()[0] * 2\n",
    "    s = torch.zeros(0,n)\n",
    "    print(s.size())\n",
    "    print(n)\n",
    "    for i in tqdm(range(len(someList))):\n",
    "\n",
    "        # retrieve the text sentence\n",
    "        sentence1 = Sentence(someList[i]['Sent_1'])\n",
    "        sentence2 = Sentence(someList[i]['Sent_2'])\n",
    "\n",
    "        # embed the sentences with our document embedding\n",
    "        document_embeddings.embed(sentence1)\n",
    "        document_embeddings.embed(sentence2)\n",
    "\n",
    "        # Calculate the element-wise product\n",
    "        productTensor = sentence1.get_embedding() * sentence2.get_embedding()\n",
    "        # Calculate the difference\n",
    "        absDiffTensor = torch.abs(sentence1.get_embedding() - sentence2.get_embedding())\n",
    "\n",
    "        # Add the concatenated vector as final embedding\n",
    "        embeddingVector = torch.cat([productTensor, absDiffTensor])\n",
    "        \n",
    "        # Adding Document embeddings to list #\n",
    "        s = torch.cat((s, embeddingVector.view(-1,n)),0)\n",
    "        \n",
    "#         torch.cuda.empty_cache()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.932432Z",
     "start_time": "2019-05-02T23:34:12.918469Z"
    }
   },
   "outputs": [],
   "source": [
    "def masterFunction(dataList, binaryOrNot, **kwargs):\n",
    "    rawList = make_List(dataList)\n",
    "    labelList = generateBinaryLabels(rawList, binaryOrNot)\n",
    "    embeddingList = generateEmbeddings(rawList, **kwargs)\n",
    "    \n",
    "    # A litttle reformatting to make the data and labels model-friendly\n",
    "    labelList = np.array(labelList).reshape(len(labelList), -1)\n",
    "    embeddingList = embeddingList.detach().numpy()\n",
    "    \n",
    "    return embeddingList, labelList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T22:34:22.665554Z",
     "start_time": "2019-04-29T22:34:22.661565Z"
    }
   },
   "source": [
    "### embeddingManager function Parameters for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    :flair: multi, multi-fast, news, news-fast or mix\n",
    "    To generate Forward/Backward combos e.g. 'multi-forward'+'multi-backward', 'news-forward-fast'+'news-backward-fast' etc\n",
    "\n",
    "    :word: glove, twitter, crawl etc\n",
    "    :BERT: 'bert-base-uncased', 'bert-large-uncased', 'bert-base-cased' and 'bert-large-cased'\n",
    "    :ELMO: 'small', 'medium' and 'original'\n",
    "    :etype: 'pool' or 'RNN'\n",
    "    :rnnType: 'GRU', 'LSTM',  'RNN_TANH' or 'RNN_RELU'\n",
    "\n",
    "    reference: https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:12.948389Z",
     "start_time": "2019-05-02T23:34:12.933445Z"
    }
   },
   "outputs": [],
   "source": [
    "binThresHold = 0.075\n",
    "def custom_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label().astype(np.int)\n",
    "    preds = (preds >= binThresHold).astype(np.int)\n",
    "    return [('f1_score', f1_score(labels, preds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:45.224484Z",
     "start_time": "2019-05-02T23:34:12.950404Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word called up!!\n",
      "\n",
      "Size of Dataset train.data 13063\n",
      "Debatable thus ignored tweet-combo count:  1533\n",
      "Final dataset size: 11530\n",
      "No of labels:  11530\n",
      "word called up!!\n",
      "Flair called up!!\n",
      "torch.Size([0, 8392])\n",
      "8392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–Ž                         | 152/11530 [00:22<34:51,  5.44it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b1eaae9097dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasterFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0membeddingsArgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasterFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dev.data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0membeddingsArgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-942067434fa7>\u001b[0m in \u001b[0;36mmasterFunction\u001b[1;34m(dataList, binaryOrNot, **kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mrawList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_List\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlabelList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateBinaryLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinaryOrNot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0membeddingList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# A litttle reformatting to make the data and labels model-friendly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-12029a81dd72>\u001b[0m in \u001b[0;36mgenerateEmbeddings\u001b[1;34m(someList, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# embed the sentences with our document embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mdocument_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mdocument_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# Calculate the element-wise product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\flair\\embeddings.py\u001b[0m in \u001b[0;36membed\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\flair\\embeddings.py\u001b[0m in \u001b[0;36membed\u001b[1;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\flair\\embeddings.py\u001b[0m in \u001b[0;36membed\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\flair\\embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m             \u001b[1;31m# get hidden states from language model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m             \u001b[0mall_hidden_states_in_lm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_representation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchars_per_chunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;31m# take first or last hidden states from language model as word representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\flair\\models\\language_model.py\u001b[0m in \u001b[0;36mget_representation\u001b[1;34m(self, strings, chars_per_chunk)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mchunks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplice_begin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlongest\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstrings\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0moutput_parts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\flair\\models\\language_model.py\u001b[0m in \u001b[0;36minit_hidden\u001b[1;34m(self, bsz)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         return (weight.new(self.nlayers, bsz, self.hidden_size).zero_().clone().detach(),\n\u001b[0m\u001b[0;32m     90\u001b[0m                 weight.new(self.nlayers, bsz, self.hidden_size).zero_().clone().detach())\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Only For parameter reference:\n",
    "embeddingManager()\n",
    "\n",
    "embeddingsArgs = {\n",
    "    'flair': True,\n",
    "#     'BERT': True,\n",
    "#       'etype':'RNN',\n",
    "#       'rnnType': 'LSTM',\n",
    "}\n",
    "\n",
    "x_train, y_train = masterFunction('train.data', True, **embeddingsArgs)\n",
    "x_valid, y_valid = masterFunction('dev.data', True, **embeddingsArgs)\n",
    "\n",
    "### XGBoost compatible data ###\n",
    "dtrain = xgb.DMatrix(x_train,y_train)\n",
    "dvalid = xgb.DMatrix(x_valid, label = y_valid)\n",
    "\n",
    "### defining parameters ###\n",
    "params = {\n",
    "          'colsample': 0.9,\n",
    "          'colsample_bytree': 0.5,\n",
    "          'eta': 0.1,\n",
    "          'max_depth': 8,\n",
    "          'min_child_weight': 6,\n",
    "          'objective': 'binary:logistic',\n",
    "          'subsample': 0.9\n",
    "          }\n",
    "\n",
    "### Training the model ###\n",
    "xgb_model = xgb.train(\n",
    "                      params,\n",
    "                      dtrain,\n",
    "                      feval= custom_eval,\n",
    "                      num_boost_round= 1000,\n",
    "                      maximize=True,\n",
    "                      evals=[(dvalid, \"Validation\")],\n",
    "                      early_stopping_rounds=30\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:45.226486Z",
     "start_time": "2019-05-02T23:34:07.537Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Reformatting test set for XGB ###\n",
    "x_test, y_test = masterFunction('test.data', True, **embeddingsArgs)\n",
    "\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "### Predicting ###\n",
    "predict = xgb_model.predict(dtest) # predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:45.227475Z",
     "start_time": "2019-05-02T23:34:07.539Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict[198])\n",
    "print(y_test[198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T23:34:45.228473Z",
     "start_time": "2019-05-02T23:34:07.541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "y_pred = np.array([1 if (predict[i] >= binThresHold) else 0 for i in range(len(predict))])\n",
    "y_true = np.array(y_test)\n",
    "score = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
